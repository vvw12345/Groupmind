"""
å¤šå¹³å° API å®¢æˆ·ç«¯ - æ”¯æŒOpenRouterã€ç¡…åŸºæµåŠ¨å’ŒAgentWorld GPT-5.1
"""
import requests
import json
import time
from typing import Dict, Any, Optional
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))
from config import OPENROUTER_CONFIG, SILICONFLOW_CONFIG

# AgentWorld é…ç½®
AGENTWORLD_CONFIG = {
    "base_url": "https://api.agentworld.top/v1/chat/completions",
    "model_api_mapping": {
        "gpt-5.1": "sk-x2hu5rCsRJ0gLSvTsfZ0ezPI1e80lEljTlnoXXcWACWu9Bci",
        "gemini-2.5-pro": "sk-qUPoKXMSka3Djbu89JeGAA9hOWiCDjoGOi8MhQpQwDYm3EnI",
        "claude-sonnet-4-20250514": "sk-ayWSyh7TnGiNlxW1OwjHgpLbNfgbJ5BsY9URx463avBx69rY",
        "gpt-4.1-mini": "sk-x2hu5rCsRJ0gLSvTsfZ0ezPI1e80lEljTlnoXXcWACWu9Bci",
        "grok-4.1": "sk-vC3CvfIwzM0TMAv3r9yIAnl2g9vZawh2nJBwSef5MgnNZ1cI"
    },
    "models": ["gpt-5.1", "gemini-2.5-pro", "claude-sonnet-4-20250514", "gpt-4.1-mini", "grok-4.1"]
}


class OpenRouterClient:
    """å¤šå¹³å°APIå®¢æˆ·ç«¯,æ”¯æŒç¡…åŸºæµåŠ¨å’ŒOpenRouter"""
    
    def __init__(self):
        # ä¼˜å…ˆä½¿ç”¨ç¡…åŸºæµåŠ¨(ä»˜è´¹ç¨³å®š)
        self.use_siliconflow = True
        
        # ç¡…åŸºæµåŠ¨é…ç½®
        self.sf_api_keys = SILICONFLOW_CONFIG["api_keys"]
        self.sf_models = SILICONFLOW_CONFIG["models"]
        self.sf_base_url = SILICONFLOW_CONFIG["base_url"]
        
        # OpenRouteré…ç½®(å¤‡ç”¨)
        self.or_api_keys = OPENROUTER_CONFIG["api_keys"]
        self.or_models = OPENROUTER_CONFIG["models"]
        self.or_base_url = OPENROUTER_CONFIG["base_url"]
        
        # å½“å‰ä½¿ç”¨çš„ç´¢å¼•
        self.current_key_index = 0
        self.current_model_index = 0
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "key_switches": 0,
            "model_switches": 0
        }
    
    def _get_current_key(self) -> str:
        """è·å–å½“å‰APIå¯†é’¥"""
        if self.use_siliconflow:
            return self.sf_api_keys[self.current_key_index]
        else:
            return self.or_api_keys[self.current_key_index]
    
    def _get_current_model(self) -> str:
        """è·å–å½“å‰æ¨¡å‹"""
        if self.use_siliconflow:
            return self.sf_models[self.current_model_index]
        else:
            return self.or_models[self.current_model_index]
    
    def _get_current_base_url(self) -> str:
        """è·å–å½“å‰APIåŸºç¡€URL"""
        if self.use_siliconflow:
            return self.sf_base_url
        else:
            return self.or_base_url
    
    def _switch_key(self):
        """åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªAPIå¯†é’¥"""
        if self.use_siliconflow:
            api_keys = self.sf_api_keys
            platform = "ç¡…åŸºæµåŠ¨"
        else:
            api_keys = self.or_api_keys
            platform = "OpenRouter"
            
        self.current_key_index = (self.current_key_index + 1) % len(api_keys)
        self.stats["key_switches"] += 1
        print(f"âš ï¸  åˆ‡æ¢{platform}APIå¯†é’¥ -> å¯†é’¥ #{self.current_key_index + 1}")
    
    def _switch_platform(self):
        """åˆ‡æ¢å¹³å°(ä»ç¡…åŸºæµåŠ¨åˆ‡æ¢åˆ°OpenRouter)"""
        if self.use_siliconflow:
            self.use_siliconflow = False
            self.current_key_index = 0
            self.current_model_index = 0
            print(f"ğŸ”„ åˆ‡æ¢åˆ°OpenRouterå¹³å°")
        else:
            print(f"âš ï¸  å·²ç»åœ¨ä½¿ç”¨OpenRouterå¹³å°")
    
    def _switch_model(self):
        """åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªæ¨¡å‹"""
        old_model = self._get_current_model()
        if self.use_siliconflow:
            models = self.sf_models
        else:
            models = self.or_models
            
        self.current_model_index = (self.current_model_index + 1) % len(models)
        new_model = self._get_current_model()
        self.stats["model_switches"] += 1
        print(f"âš ï¸  åˆ‡æ¢æ¨¡å‹: {old_model} -> {new_model}")
    
    def call_llm(
        self, 
        prompt: str, 
        max_retries: int = 50,
        temperature: float = 0.8,
        max_tokens: int = 4000
    ) -> Optional[str]:
        """
        è°ƒç”¨LLM API,æ”¯æŒè‡ªåŠ¨é‡è¯•å’Œåˆ‡æ¢
        
        Args:
            prompt: æç¤ºè¯
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§tokenæ•°
            
        Returns:
            ç”Ÿæˆçš„æ–‡æœ¬,å¤±è´¥è¿”å›None
        """
        self.stats["total_requests"] += 1
        
        for attempt in range(max_retries):
            try:
                headers = {
                    "Authorization": f"Bearer {self._get_current_key()}",
                    "Content-Type": "application/json"
                }
                
                payload = {
                    "model": self._get_current_model(),
                    "messages": [
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": temperature,
                    "max_tokens": max_tokens
                }
                
                response = requests.post(
                    self._get_current_base_url(),
                    headers=headers,
                    json=payload,
                    timeout=60
                )
                
                # æ£€æŸ¥å“åº”çŠ¶æ€
                if response.status_code == 200:
                    result = response.json()
                    content = result["choices"][0]["message"]["content"]
                    self.stats["successful_requests"] += 1
                    return content
                
                # å¤„ç†é™æµé”™è¯¯ (429)
                elif response.status_code == 429:
                    error_data = response.json()
                    error_msg = error_data.get("error", {}).get("message", "")
                    
                    # å¦‚æœæ˜¯ç¡…åŸºæµåŠ¨ä¸”å·²ç»å°è¯•è¿‡æ‰€æœ‰å¯†é’¥,åˆ‡æ¢åˆ°OpenRouter
                    if self.use_siliconflow and self.current_key_index >= len(self.sf_api_keys) - 1:
                        print(f"âš ï¸  ç¡…åŸºæµåŠ¨å¯†é’¥å·²ç”¨å®Œ,åˆ‡æ¢åˆ°OpenRouter...")
                        self._switch_platform()
                    else:
                        # é‡åˆ°é™æµç›´æ¥åˆ‡æ¢APIå¯†é’¥
                        print(f"â³ é‡åˆ°é™æµ(429),åˆ‡æ¢APIå¯†é’¥... (å°è¯• {attempt + 1}/{max_retries})")
                        self._switch_key()
                    
                    time.sleep(0.5)  # çŸ­æš‚ç­‰å¾…
                
                # å¤„ç†è®¤è¯é”™è¯¯ (401) - æ— æ•ˆå¯†é’¥,å¿«é€Ÿåˆ‡æ¢
                elif response.status_code == 401:
                    print(f"âš ï¸  å¯†é’¥ #{self.current_key_index + 1} æ— æ•ˆ(401),åˆ‡æ¢...")
                    # å¦‚æœæ˜¯ç¡…åŸºæµåŠ¨ä¸”å·²ç»å°è¯•è¿‡æ‰€æœ‰å¯†é’¥,åˆ‡æ¢åˆ°OpenRouter
                    if self.use_siliconflow and self.current_key_index >= len(self.sf_api_keys) - 1:
                        print(f"âš ï¸  ç¡…åŸºæµåŠ¨å¯†é’¥å·²ç”¨å®Œ,åˆ‡æ¢åˆ°OpenRouter...")
                        self._switch_platform()
                    else:
                        self._switch_key()
                    time.sleep(0.2)  # æ— æ•ˆå¯†é’¥å¿«é€Ÿåˆ‡æ¢
                
                # å¤„ç†å…¶ä»–é”™è¯¯
                else:
                    print(f"âŒ APIé”™è¯¯ {response.status_code}: {response.text[:100]}")
                    self._switch_key()
                    time.sleep(1)
                    
            except requests.exceptions.Timeout:
                print(f"â±ï¸  è¯·æ±‚è¶…æ—¶,é‡è¯•... (å°è¯• {attempt + 1}/{max_retries})")
                time.sleep(2)
                
            except Exception as e:
                print(f"âŒ æœªçŸ¥é”™è¯¯: {str(e)}")
                self._switch_key()
                time.sleep(2)
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        self.stats["failed_requests"] += 1
        print(f"âŒ è¯·æ±‚å¤±è´¥,å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})")
        return None
    
    def print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "="*50)
        print("ğŸ“Š APIè°ƒç”¨ç»Ÿè®¡")
        print("="*50)
        print(f"æ€»è¯·æ±‚æ•°: {self.stats['total_requests']}")
        print(f"æˆåŠŸ: {self.stats['successful_requests']}")
        print(f"å¤±è´¥: {self.stats['failed_requests']}")
        print(f"APIå¯†é’¥åˆ‡æ¢æ¬¡æ•°: {self.stats['key_switches']}")
        print(f"æ¨¡å‹åˆ‡æ¢æ¬¡æ•°: {self.stats['model_switches']}")
        platform = "ç¡…åŸºæµåŠ¨" if self.use_siliconflow else "OpenRouter"
        print(f"å½“å‰å¹³å°: {platform}")
        print(f"å½“å‰ä½¿ç”¨: å¯†é’¥ #{self.current_key_index + 1}, æ¨¡å‹ {self._get_current_model()}")
        print("="*50 + "\n")


class AgentWorldClient:
    """AgentWorld GPT-5.1 APIå®¢æˆ·ç«¯"""
    
    def __init__(self):
        self.model_api_mapping = AGENTWORLD_CONFIG["model_api_mapping"]
        self.base_url = AGENTWORLD_CONFIG["base_url"]
        self.models = AGENTWORLD_CONFIG["models"]
        self.current_model_index = 0
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "model_switches": 0
        }
        
        print(f"ğŸš€ AgentWorld å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ¯ å½“å‰æ¨¡å‹: {self.get_current_model()}")
        print(f"ğŸ”‘ æ¨¡å‹APIæ˜ å°„: {len(self.model_api_mapping)}ä¸ª")
    
    def get_current_model(self) -> str:
        """è·å–å½“å‰æ¨¡å‹"""
        return self.models[self.current_model_index]
    
    def get_current_api_key(self) -> str:
        """è·å–å½“å‰æ¨¡å‹å¯¹åº”çš„APIå¯†é’¥"""
        current_model = self.get_current_model()
        return self.model_api_mapping[current_model]
    
    def switch_model(self):
        """åˆ‡æ¢æ¨¡å‹"""
        old_model = self.get_current_model()
        self.current_model_index = (self.current_model_index + 1) % len(self.models)
        new_model = self.get_current_model()
        self.stats["model_switches"] += 1
        print(f"ğŸ”„ åˆ‡æ¢æ¨¡å‹: {old_model} -> {new_model}")
    
    
    def call_llm(
        self, 
        prompt: str, 
        max_retries: int = 10,
        temperature: float = 0.8,
        max_tokens: int = 4000,
        stream: bool = False
    ) -> Optional[str]:
        """
        è°ƒç”¨AgentWorld GPT-5.1 API
        
        Args:
            prompt: æç¤ºè¯
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§tokenæ•°
            stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
            
        Returns:
            ç”Ÿæˆçš„æ–‡æœ¬,å¤±è´¥è¿”å›None
        """
        self.stats["total_requests"] += 1
        
        for attempt in range(max_retries):
            try:
                headers = {
                    'Accept': 'text/event-stream' if stream else 'application/json',
                    'Authorization': f'Bearer {self.get_current_api_key()}',
                    'Content-Type': 'application/json'
                }
                
                payload = {
                    "model": self.get_current_model(),
                    "messages": [
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": temperature,
                    "max_tokens": max_tokens,
                    "stream": stream
                }
                
                response = requests.post(
                    self.base_url,
                    headers=headers,
                    json=payload,
                    timeout=120,  # GPT-5.1å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´
                    stream=stream
                )
                
                if response.status_code == 200:
                    if stream:
                        # å¤„ç†æµå¼å“åº”
                        content = ""
                        for line in response.iter_lines():
                            if line:
                                line = line.decode('utf-8')
                                if line.startswith('data: '):
                                    if line == 'data: [DONE]':
                                        break
                                    try:
                                        data = json.loads(line[6:])  # å»æ‰ "data: " å‰ç¼€
                                        if 'choices' in data and len(data['choices']) > 0:
                                            delta = data['choices'][0].get('delta', {})
                                            if 'content' in delta:
                                                content += delta['content']
                                    except json.JSONDecodeError:
                                        continue
                        self.stats["successful_requests"] += 1
                        return content
                    else:
                        # å¤„ç†æ™®é€šå“åº”
                        result = response.json()
                        content = result["choices"][0]["message"]["content"]
                        self.stats["successful_requests"] += 1
                        return content
                
                # å¤„ç†é™æµé”™è¯¯ (429)
                elif response.status_code == 429:
                    print(f"â³ é‡åˆ°é™æµ(429),ç­‰å¾…é‡è¯•... (å°è¯• {attempt + 1}/{max_retries})")
                    time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                
                # å¤„ç†è®¤è¯é”™è¯¯ (401) - å°è¯•åˆ‡æ¢æ¨¡å‹
                elif response.status_code == 401:
                    print(f"âŒ è®¤è¯å¤±è´¥(401),å°è¯•åˆ‡æ¢æ¨¡å‹...")
                    self.switch_model()
                    time.sleep(1)
                
                # å¤„ç†æ¨¡å‹é”™è¯¯,å°è¯•åˆ‡æ¢æ¨¡å‹
                elif response.status_code == 400:
                    error_text = response.text
                    if "model" in error_text.lower():
                        print(f"âš ï¸  æ¨¡å‹é”™è¯¯,å°è¯•åˆ‡æ¢æ¨¡å‹...")
                        self.switch_model()
                        time.sleep(1)
                    else:
                        print(f"âŒ è¯·æ±‚é”™è¯¯ {response.status_code}: {response.text[:200]}")
                        time.sleep(2)
                
                # å¤„ç†å…¶ä»–é”™è¯¯
                else:
                    print(f"âŒ APIé”™è¯¯ {response.status_code}: {response.text[:200]}")
                    time.sleep(2)
                    
            except requests.exceptions.Timeout:
                print(f"â±ï¸  è¯·æ±‚è¶…æ—¶,é‡è¯•... (å°è¯• {attempt + 1}/{max_retries})")
                time.sleep(5)
                
            except Exception as e:
                print(f"âŒ æœªçŸ¥é”™è¯¯: {str(e)}")
                time.sleep(3)
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        self.stats["failed_requests"] += 1
        print(f"âŒ è¯·æ±‚å¤±è´¥,å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})")
        return None
    
    def print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "="*50)
        print("ğŸ“Š AgentWorld GPT-5.1 APIè°ƒç”¨ç»Ÿè®¡")
        print("="*50)
        print(f"æ€»è¯·æ±‚æ•°: {self.stats['total_requests']}")
        print(f"æˆåŠŸ: {self.stats['successful_requests']}")
        print(f"å¤±è´¥: {self.stats['failed_requests']}")
        print(f"æˆåŠŸç‡: {self.stats['successful_requests']/self.stats['total_requests']*100:.1f}%" if self.stats['total_requests'] > 0 else "æˆåŠŸç‡: 0%")
        print(f"æ¨¡å‹åˆ‡æ¢æ¬¡æ•°: {self.stats['model_switches']}")
        print(f"å½“å‰æ¨¡å‹: {self.get_current_model()}")
        print("="*50 + "\n")
