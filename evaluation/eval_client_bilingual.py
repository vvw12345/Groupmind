"""
åŒè¯­è¯„æµ‹APIå®¢æˆ·ç«¯ - æ”¯æŒä¸­è‹±æ–‡æ•°æ®è¯„æµ‹
"""
import requests
import json
import time
import threading
from typing import Dict, Any, Optional, List
from pathlib import Path
import sys
from queue import Queue
import random

# æ·»åŠ ä¸»ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))
from config import OPENROUTER_CONFIG, SILICONFLOW_CONFIG, YUNWU_CONFIG
# å¯¼å…¥AgentWorldé…ç½®
sys.path.append(str(Path(__file__).parent.parent / "data_generator"))
from api_client import AGENTWORLD_CONFIG

class BilingualEvaluationClient:
    """åŒè¯­è¯„æµ‹APIå®¢æˆ·ç«¯"""
    
    def __init__(self, models: List[str] = None, use_siliconflow: bool = False, use_agentworld: bool = False, use_yunwu: bool = False, language: str = "zh", evaluation_mode: str = "full"):
        self.use_siliconflow = use_siliconflow
        self.use_agentworld = use_agentworld
        self.use_yunwu = use_yunwu
        self.language = language  # "zh" for Chinese, "en" for English
        self.evaluation_mode = evaluation_mode  # "full" or "limited"
        
        if use_yunwu:
            self.base_url = YUNWU_CONFIG["base_url"]
            self.api_keys = YUNWU_CONFIG["api_keys"]
            self.models = models or YUNWU_CONFIG["models"]
            # å­˜å‚¨æ¨¡å‹ä¸“ç”¨å¯†é’¥é…ç½®
            self.model_specific_keys = YUNWU_CONFIG.get("model_specific_keys", {})
        elif use_agentworld:
            self.base_url = AGENTWORLD_CONFIG["base_url"]
            self.model_api_mapping = AGENTWORLD_CONFIG["model_api_mapping"]
            self.models = models or ["gpt-5.1", "gemini-2.5-pro"]
            self.api_keys = list(self.model_api_mapping.values())  # ä¸ºå…¼å®¹æ€§åˆ›å»ºapi_keysåˆ—è¡¨
            self.model_specific_keys = {}
        elif use_siliconflow:
            self.base_url = SILICONFLOW_CONFIG["base_url"]
            self.api_keys = SILICONFLOW_CONFIG["api_keys"]
            self.models = models or [
                "Qwen/Qwen2.5-7B-Instruct",
                "Qwen/Qwen2.5-14B-Instruct"
            ]
            self.model_specific_keys = {}
        else:
            self.base_url = OPENROUTER_CONFIG["base_url"]
            self.api_keys = OPENROUTER_CONFIG["api_keys"]
            self.models = models or [
                "moonshotai/kimi-k2:free",
                "z-ai/glm-4.5-air:free"
            ]
            self.model_specific_keys = {}
        
        # APIä½¿ç”¨çŠ¶æ€
        self.current_key_index = 0
        self.current_model_index = 0
        self.lock = threading.Lock()
        
        # é™æµè®¾ç½®
        self.rate_limit_delay = 0.5  # æ¯æ¬¡è¯·æ±‚é—´éš”
        self.key_last_used = {}  # è®°å½•æ¯ä¸ªå¯†é’¥çš„æœ€åä½¿ç”¨æ—¶é—´
        
        # é‡è¯•è®¾ç½®
        self.max_retries = 10
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'key_switches': 0,
            'rate_limit_hits': 0,
            'model_usage': {model: 0 for model in self.models}
        }
        
        mode_names = {
            'full': 'å…¨çŸ¥è§†è§’',
            'limited': 'æœ‰é™ä¿¡æ¯', 
            'chat': 'é—²èŠæ¨¡å¼'
        }
        mode_display = mode_names.get(evaluation_mode, evaluation_mode)
        print(f"ğŸ¤– è¯„æµ‹å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ (è¯­è¨€: {'ä¸­æ–‡' if language == 'zh' else 'è‹±æ–‡'}, æ¨¡å¼: {mode_display})")
        if use_agentworld:
            print(f"ğŸ“Š æ¨¡å‹APIæ˜ å°„: {len(self.model_api_mapping)}ä¸ª")
        else:
            print(f"ğŸ“Š å¯ç”¨APIå¯†é’¥: {len(self.api_keys)}ä¸ª")
        print(f"ğŸ”„ æœ€å¤§é‡è¯•æ¬¡æ•°: {self.max_retries}æ¬¡")
        print(f"ğŸ¯ è¯„æµ‹æ¨¡å‹: {', '.join(self.models)}")
        if len(self.models) > 1:
            print(f"ğŸ’ª ç†è®ºæœ€å¤§å°è¯•æ¬¡æ•°: {self.max_retries * len(self.models)}æ¬¡")
    
    def _get_current_model(self) -> str:
        """è·å–å½“å‰æ¨¡å‹"""
        return self.models[self.current_model_index]
    
    def _get_current_key(self, model: str = None) -> str:
        """è·å–å½“å‰APIå¯†é’¥"""
        if self.use_agentworld and model:
            # AgentWorldæ¨¡å¼ï¼šæ ¹æ®æ¨¡å‹è·å–å¯¹åº”çš„APIå¯†é’¥
            return self.model_api_mapping.get(model, list(self.model_api_mapping.values())[0])
        elif model and model in self.model_specific_keys:
            # æ¨¡å‹ä¸“ç”¨å¯†é’¥ï¼šä¼˜å…ˆä½¿ç”¨æ¨¡å‹ä¸“ç”¨å¯†é’¥
            return self.model_specific_keys[model]
        else:
            # å…¶ä»–æ¨¡å¼ï¼šä½¿ç”¨å¯†é’¥è½®æ¢
            return self.api_keys[self.current_key_index]
    
    def _switch_key(self):
        """åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªAPIå¯†é’¥"""
        current_model = self._get_current_model()
        # AgentWorldæ¨¡å¼æˆ–ä½¿ç”¨æ¨¡å‹ä¸“ç”¨å¯†é’¥æ—¶ä¸éœ€è¦åˆ‡æ¢å¯†é’¥
        if not self.use_agentworld and current_model not in self.model_specific_keys:
            with self.lock:
                self.current_key_index = (self.current_key_index + 1) % len(self.api_keys)
                self.stats['key_switches'] += 1
    
    def _switch_model(self):
        """åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªæ¨¡å‹"""
        with self.lock:
            self.current_model_index = (self.current_model_index + 1) % len(self.models)
            print(f"ğŸ”„ åˆ‡æ¢æ¨¡å‹: {self._get_current_model()}")
    
    def _apply_rate_limit(self):
        """åº”ç”¨é™æµå»¶è¿Ÿ"""
        current_time = time.time()
        current_key = self._get_current_key()
        
        # æ£€æŸ¥è¯¥å¯†é’¥çš„ä¸Šæ¬¡ä½¿ç”¨æ—¶é—´
        if current_key in self.key_last_used:
            time_since_last = current_time - self.key_last_used[current_key]
            if time_since_last < self.rate_limit_delay:
                sleep_time = self.rate_limit_delay - time_since_last
                time.sleep(sleep_time)
        
        self.key_last_used[current_key] = time.time()
    
    def call_llm(self, messages: List[Dict], temperature: float = 0.3) -> Optional[str]:
        """è°ƒç”¨LLM API"""
        self.stats['total_requests'] += 1
        
        for attempt in range(self.max_retries):
            try:
                # åº”ç”¨é™æµ
                self._apply_rate_limit()
                
                current_model = self._get_current_model()
                current_key = self._get_current_key(current_model)
                
                headers = {
                    "Authorization": f"Bearer {current_key}",
                    "Content-Type": "application/json"
                }
                
                payload = {
                    "model": current_model,
                    "messages": messages,
                    "temperature": temperature,
                    "max_tokens": 1000
                }
                
                response = requests.post(
                    self.base_url,
                    headers=headers,
                    json=payload,
                    timeout=30
                )
                
                if response.status_code == 200:
                    data = response.json()
                    content = data['choices'][0]['message']['content']
                    
                    # æ›´æ–°ç»Ÿè®¡
                    self.stats['successful_requests'] += 1
                    self.stats['model_usage'][current_model] += 1
                    
                    return content
                
                elif response.status_code == 429:
                    # é™æµé”™è¯¯
                    self.stats['rate_limit_hits'] += 1
                    print(f"âš ï¸ é™æµé”™è¯¯ (429), å°è¯• {attempt + 1}/{self.max_retries}, "
                          f"å½“å‰å¯†é’¥: {self.current_key_index + 1}/{len(self.api_keys) if not self.use_agentworld else 'N/A'}")
                    
                    if attempt < self.max_retries - 1:
                        # å¦‚æœæœ‰å¤šä¸ªAPIå¯†é’¥ï¼Œåˆ™åˆ‡æ¢ï¼›å¦åˆ™ä¿æŒå½“å‰å¯†é’¥
                        if not self.use_agentworld and len(self.api_keys) > 1:
                            self._switch_key()
                            print(f"ğŸ”„ åˆ‡æ¢APIå¯†é’¥: {self.current_key_index+1}/{len(self.api_keys)}")
                        
                        sleep_time = 1.0  # å›ºå®š1ç§’å»¶è¿Ÿ
                        print(f"â±ï¸ å»¶è¿Ÿ {sleep_time:.1f}s åé‡è¯•")
                        time.sleep(sleep_time)
                    
                elif response.status_code == 401:
                    # è®¤è¯é”™è¯¯ï¼Œåˆ‡æ¢å¯†é’¥
                    print(f"âŒ è®¤è¯é”™è¯¯ (401), åˆ‡æ¢å¯†é’¥")
                    self._switch_key()
                    
                else:
                    print(f"âŒ APIé”™è¯¯: {response.status_code} - {response.text}")
                    
            except requests.exceptions.Timeout:
                print(f"â° è¯·æ±‚è¶…æ—¶, å°è¯• {attempt + 1}/{self.max_retries}")
                
            except Exception as e:
                print(f"âŒ è¯·æ±‚å¼‚å¸¸: {e}")
                
            # å¤±è´¥é‡è¯•å‰çš„å»¶è¿Ÿ
            if attempt < self.max_retries - 1:
                time.sleep(random.uniform(1, 2))
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        self.stats['failed_requests'] += 1
        return None
    
    def evaluate_sample(self, sample: Dict, task_type: str) -> Optional[Dict]:
        """è¯„æµ‹å•ä¸ªæ ·æœ¬çš„ç‰¹å®šä»»åŠ¡"""
        try:
            # æ„å»ºè¯„æµ‹prompt
            prompt = self._build_evaluation_prompt(sample, task_type)
            
            # æ ¹æ®è¯­è¨€å’Œè¯„ä¼°æ¨¡å¼é€‰æ‹©system prompt
            if self.evaluation_mode == "limited":
                if self.language == "zh":
                    system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¯¹è¯åˆ†æä¸“å®¶ã€‚è¯·ä»¥å®¡æ…çš„æ€åº¦ä»”ç»†è§‚å¯Ÿå¯¹è¯ä¸­çš„ç»†èŠ‚ï¼Œä»è¯­è¨€ã€è¯­è°ƒã€äº’åŠ¨æ¨¡å¼ç­‰æ–¹é¢è¿›è¡Œæ¨ç†åˆ†æã€‚"
                else:
                    system_prompt = "You are a professional dialogue analysis expert. Please approach the analysis with caution and carefully observe details in the conversation, reasoning from language, tone, and interaction patterns."
            elif self.evaluation_mode == "chat":
                # Chatæ¨¡å¼æ ¹æ®æ˜¯å¦æœ‰å®Œæ•´è§’è‰²ä¿¡æ¯æ¥è°ƒæ•´ç³»ç»Ÿæç¤º
                if self._has_full_persona_info(sample):
                    # æœ‰å®Œæ•´è§’è‰²ä¿¡æ¯ï¼Œä½¿ç”¨å…¨çŸ¥è§†è§’æç¤º
                    if self.language == "zh":
                        system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¯¹è¯åˆ†æä¸“å®¶ã€‚è¯·ä»”ç»†åˆ†æåŒ…å«é—²èŠå†…å®¹çš„å¤šäººå¯¹è¯åœºæ™¯ï¼Œä½ å¯ä»¥çœ‹åˆ°æ¯ä¸ªè§’è‰²çš„éšè—åŠ¨æœºå’Œé›†ä½“æ„å›¾ï¼Œæ³¨æ„åŒºåˆ†é—²èŠè¯é¢˜å’Œæ ¸å¿ƒå†²çªå†…å®¹ã€‚"
                    else:
                        system_prompt = "You are a professional dialogue analysis expert. Please carefully analyze multi-person dialogue scenarios that include casual chat content. You can see each character's hidden motives and collective intentions. Distinguish between casual topics and core conflict content."
                else:
                    # æ²¡æœ‰å®Œæ•´è§’è‰²ä¿¡æ¯ï¼Œä½¿ç”¨æœ‰é™ä¿¡æ¯æç¤º
                    if self.language == "zh":
                        system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¯¹è¯åˆ†æä¸“å®¶ã€‚è¯·ä»”ç»†åˆ†æåŒ…å«é—²èŠå†…å®¹çš„å¤šäººå¯¹è¯åœºæ™¯ï¼Œæ³¨æ„åŒºåˆ†é—²èŠè¯é¢˜å’Œæ ¸å¿ƒå†²çªå†…å®¹ã€‚"
                    else:
                        system_prompt = "You are a professional dialogue analysis expert. Please carefully analyze multi-person dialogue scenarios that include casual chat content, distinguishing between casual topics and core conflict content."
            else:
                if self.language == "zh":
                    system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¯¹è¯åˆ†æä¸“å®¶ï¼Œè¯·ä»”ç»†åˆ†æç»™å®šçš„å¤šäººå¯¹è¯åœºæ™¯ã€‚"
                else:
                    system_prompt = "You are a professional dialogue analysis expert. Please carefully analyze the given multi-person dialogue scenario."
            
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ]
            
            # è°ƒç”¨API
            response = self.call_llm(messages)
            if not response:
                return None
            
            # è§£æå“åº”
            result = self._parse_evaluation_response(response, sample, task_type)
            return result
            
        except Exception as e:
            print(f"âŒ è¯„æµ‹æ ·æœ¬å¤±è´¥: {e}")
            return None
    
    def _build_evaluation_prompt(self, sample: Dict, task_type: str) -> str:
        """æ„å»ºè¯„æµ‹prompt - æ”¯æŒä¸­è‹±æ–‡å’Œä¸åŒè¯„ä¼°æ¨¡å¼"""
        
        if self.evaluation_mode == "limited":
            # æœ‰é™ä¿¡æ¯æ¨¡å¼ï¼šåªæä¾›åŸºæœ¬èº«ä»½å’Œå¯¹è¯
            if self.language == "zh":
                return self._build_chinese_limited_prompt(sample, task_type)
            else:
                return self._build_english_limited_prompt(sample, task_type)
        elif self.evaluation_mode == "chat":
            # é—²èŠæ¨¡å¼ï¼šå¯ä»¥æ˜¯å…¨çŸ¥è§†è§’æˆ–æœ‰é™ä¿¡æ¯ï¼Œä½†ä½¿ç”¨é—²èŠæ•°æ®é›†
            # è¿™é‡Œæˆ‘ä»¬éœ€è¦æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„è§’è‰²ä¿¡æ¯æ¥å†³å®šä½¿ç”¨å“ªç§æ¨¡å¼
            if self._has_full_persona_info(sample):
                # å¦‚æœæœ‰å®Œæ•´çš„è§’è‰²ä¿¡æ¯ï¼Œä½¿ç”¨å…¨çŸ¥è§†è§’
                if self.language == "zh":
                    return self._build_chinese_chat_full_prompt(sample, task_type)
                else:
                    return self._build_english_chat_full_prompt(sample, task_type)
            else:
                # å¦åˆ™ä½¿ç”¨æœ‰é™ä¿¡æ¯æ¨¡å¼
                if self.language == "zh":
                    return self._build_chinese_limited_prompt(sample, task_type)
                else:
                    return self._build_english_limited_prompt(sample, task_type)
        else:
            # å…¨çŸ¥è§†è§’æ¨¡å¼ï¼šæä¾›å®Œæ•´ä¿¡æ¯
            if self.language == "zh":
                return self._build_chinese_prompt(sample, task_type)
            else:
                return self._build_english_prompt(sample, task_type)
    
    def _build_chinese_prompt(self, sample: Dict, task_type: str) -> str:
        """æ„å»ºä¸­æ–‡è¯„æµ‹prompt"""
        scenario = sample['scenario_setup']
        dialogue = sample['dialogue_transcript']
        trigger = sample['evaluation_trigger']
        labels = sample['evaluation_labels']
        
        # æ„å»ºå¯¹è¯æ–‡æœ¬
        dialogue_text = "\n".join([
            f"Turn {turn['turn']}: {turn['speaker']}: {turn['line']}"
            for turn in dialogue
        ])
        
        base_context = f"""
åœºæ™¯æè¿°: {scenario['scenario_description']}

è§’è‰²è®¾å®š:
{chr(10).join([f"- {p['name']}: å…¬å¼€ç›®æ ‡({p['public_goal']}) | éšè—åŠ¨æœº({p['private_motive']})" for p in scenario['personas']])}

éšè—é›†ä½“æ„å›¾: {scenario['hidden_collective_intent']}

å¯¹è¯å†…å®¹:
{dialogue_text}

å…³é”®æ—¶åˆ»: Turn {trigger['trigger_turn_id']} - {trigger['trigger_description']}
"""
        
        if task_type == "atmosphere_recognition":
            question = labels['atmosphere_recognition']
            return f"""{base_context}

è¯·åˆ†æåœ¨å…³é”®æ—¶åˆ»åï¼Œç¾¤ä½“æ°›å›´æœ€çªå‡ºçš„å˜åŒ–æ˜¯ä»€ä¹ˆï¼Ÿ

é—®é¢˜: {question['question']}

é€‰é¡¹:
{chr(10).join([f"{i+1}. {opt[3:]}" for i, opt in enumerate(question['mcq_options'])])}

è¯·åªå›ç­”é€‰é¡¹ç¼–å·(1-6)ï¼Œä¸è¦è§£é‡Šã€‚"""

        elif task_type == "ky_test":
            question = labels['ky_test']
            return f"""{base_context}

è¯·åˆ†æåœ¨å½“å‰æƒ…å†µä¸‹ï¼Œæœ€åˆæ—¶å®œçš„å›åº”åº”è¯¥æ˜¯ä»€ä¹ˆï¼Ÿ

é—®é¢˜: {question['question']}

é€‰é¡¹:
{chr(10).join([f"{i+1}. {opt[3:]}" for i, opt in enumerate(question['mcq_options'])])}

è¯·åªå›ç­”é€‰é¡¹ç¼–å·(1-6)ï¼Œä¸è¦è§£é‡Šã€‚"""

        elif task_type == "subtext_deciphering":
            question = labels['subtext_deciphering']
            return f"""{base_context}

è¯·åˆ†æä»¥ä¸‹å¯¹è¯ä¸­çš„æ½œå°è¯å«ä¹‰ï¼š

é—®é¢˜: {question['question']}

é€‰é¡¹:
{chr(10).join([f"{i+1}. {opt[3:]}" for i, opt in enumerate(question['mcq_options'])])}

è¯·åªå›ç­”é€‰é¡¹ç¼–å·(1-6)ï¼Œä¸è¦è§£é‡Šã€‚"""
        
        return ""
    
    def _build_chinese_limited_prompt(self, sample: Dict, task_type: str) -> str:
        """æ„å»ºä¸­æ–‡æœ‰é™ä¿¡æ¯è¯„æµ‹prompt - åªæä¾›åŸºæœ¬èº«ä»½å’Œå¯¹è¯"""
        scenario = sample['scenario_setup']
        dialogue = sample['dialogue_transcript']
        trigger = sample['evaluation_trigger']
        labels = sample['evaluation_labels']
        
        # æ„å»ºå¯¹è¯æ–‡æœ¬
        dialogue_text = "\n".join([
            f"Turn {turn['turn']}: {turn['speaker']}: {turn['line']}"
            for turn in dialogue
        ])
        
        # åªæä¾›åŸºæœ¬è§’è‰²åç§°ï¼ˆä¸åŒ…å«ä»»ä½•ç›®æ ‡ã€åŠ¨æœºå’Œé›†ä½“æ„å›¾ï¼‰
        basic_personas = "\n".join([f"- {p['name']}" for p in scenario['personas']])
        
        base_context = f"""
åœºæ™¯æè¿°: {scenario['scenario_description']}

è§’è‰²è®¾å®š:
{basic_personas}

å¯¹è¯å†…å®¹:
{dialogue_text}

å…³é”®æ—¶åˆ»: Turn {trigger['trigger_turn_id']} - {trigger['trigger_description']}
"""
        
        if task_type == "atmosphere_recognition":
            question = labels['atmosphere_recognition']
            return f"""{base_context}

è¯·ä»”ç»†è§‚å¯Ÿå¯¹è¯ä¸­çš„è¯­è¨€ç»†èŠ‚ã€è¯´è¯æ–¹å¼å’Œäº’åŠ¨æ¨¡å¼ï¼ŒåŸºäºä½ èƒ½è§‚å¯Ÿåˆ°çš„å…·ä½“çº¿ç´¢è¿›è¡Œå®¡æ…æ¨ç†ã€‚

è¯·åˆ†æåœ¨å…³é”®æ—¶åˆ»åï¼Œç¾¤ä½“æ°›å›´æœ€çªå‡ºçš„å˜åŒ–æ˜¯ä»€ä¹ˆï¼Ÿ

é—®é¢˜: {question['question']}

é€‰é¡¹:
{chr(10).join([f"{i+1}. {opt[3:]}" for i, opt in enumerate(question['mcq_options'])])}

è¯·åªå›ç­”é€‰é¡¹ç¼–å·(1-6)ï¼Œä¸è¦è§£é‡Šã€‚"""

        elif task_type == "ky_test":
            question = labels['ky_test']
            return f"""{base_context}

è¯·ä»”ç»†è§‚å¯Ÿå¯¹è¯ä¸­çš„è¯­è¨€ç»†èŠ‚ã€è¯´è¯æ–¹å¼å’Œäº’åŠ¨æ¨¡å¼ï¼ŒåŸºäºä½ èƒ½è§‚å¯Ÿåˆ°çš„å…·ä½“çº¿ç´¢è¿›è¡Œå®¡æ…æ¨ç†ã€‚

è¯·åˆ†æåœ¨å½“å‰æƒ…å†µä¸‹ï¼Œæœ€åˆæ—¶å®œçš„å›åº”åº”è¯¥æ˜¯ä»€ä¹ˆï¼Ÿ

é—®é¢˜: {question['question']}

é€‰é¡¹:
{chr(10).join([f"{i+1}. {opt[3:]}" for i, opt in enumerate(question['mcq_options'])])}

è¯·åªå›ç­”é€‰é¡¹ç¼–å·(1-6)ï¼Œä¸è¦è§£é‡Šã€‚"""

        elif task_type == "subtext_deciphering":
            question = labels['subtext_deciphering']
            return f"""{base_context}

è¯·ä»”ç»†è§‚å¯Ÿå¯¹è¯ä¸­çš„è¯­è¨€ç»†èŠ‚ã€è¯´è¯æ–¹å¼å’Œäº’åŠ¨æ¨¡å¼ï¼ŒåŸºäºä½ èƒ½è§‚å¯Ÿåˆ°çš„å…·ä½“çº¿ç´¢è¿›è¡Œå®¡æ…æ¨ç†ã€‚

è¯·åˆ†æä»¥ä¸‹å¯¹è¯ä¸­çš„æ½œå°è¯å«ä¹‰ï¼š

é—®é¢˜: {question['question']}

é€‰é¡¹:
{chr(10).join([f"{i+1}. {opt[3:]}" for i, opt in enumerate(question['mcq_options'])])}

è¯·åªå›ç­”é€‰é¡¹ç¼–å·(1-6)ï¼Œä¸è¦è§£é‡Šã€‚"""
        
        return ""
    
    def _build_english_prompt(self, sample: Dict, task_type: str) -> str:
        """æ„å»ºè‹±æ–‡è¯„æµ‹prompt"""
        scenario = sample['scenario_setup']
        dialogue = sample['dialogue_transcript']
        trigger = sample['evaluation_trigger']
        labels = sample['evaluation_labels']
        
        # æ„å»ºå¯¹è¯æ–‡æœ¬
        dialogue_text = "\n".join([
            f"Turn {turn['turn']}: {turn['speaker']}: {turn['line']}"
            for turn in dialogue
        ])
        
        base_context = f"""
Scenario Description: {scenario['scenario_description']}

Character Settings:
{chr(10).join([f"- {p['name']}: Public Goal({p['public_goal']}) | Private Motive({p['private_motive']})" for p in scenario['personas']])}

Hidden Collective Intent: {scenario['hidden_collective_intent']}

Dialogue Content:
{dialogue_text}

Critical Moment: Turn {trigger['trigger_turn_id']} - {trigger['trigger_description']}
"""
        
        if task_type == "atmosphere_recognition":
            question = labels['atmosphere_recognition']
            return f"""{base_context}

Please analyze what the most prominent change in group atmosphere is after the critical moment.

Question: {question['question']}

Options:
{chr(10).join([f"{i+1}. {opt[3:]}" for i, opt in enumerate(question['mcq_options'])])}

Please only answer with the option number (1-6), no explanation needed."""

        elif task_type == "ky_test":
            question = labels['ky_test']
            return f"""{base_context}

Please analyze what the most appropriate response should be in the current situation.

Question: {question['question']}

Options:
{chr(10).join([f"{i+1}. {opt[3:]}" for i, opt in enumerate(question['mcq_options'])])}

Please only answer with the option number (1-6), no explanation needed."""

        elif task_type == "subtext_deciphering":
            question = labels['subtext_deciphering']
            return f"""{base_context}

Please analyze the subtext meaning in the following dialogue:

Question: {question['question']}

Options:
{chr(10).join([f"{i+1}. {opt[3:]}" for i, opt in enumerate(question['mcq_options'])])}

Please only answer with the option number (1-6), no explanation needed."""
        
        return ""
    
    def _build_english_limited_prompt(self, sample: Dict, task_type: str) -> str:
        """æ„å»ºè‹±æ–‡æœ‰é™ä¿¡æ¯è¯„æµ‹prompt - åªæä¾›åŸºæœ¬èº«ä»½å’Œå¯¹è¯"""
        scenario = sample['scenario_setup']
        dialogue = sample['dialogue_transcript']
        trigger = sample['evaluation_trigger']
        labels = sample['evaluation_labels']
        
        # æ„å»ºå¯¹è¯æ–‡æœ¬
        dialogue_text = "\n".join([
            f"Turn {turn['turn']}: {turn['speaker']}: {turn['line']}"
            for turn in dialogue
        ])
        
        # åªæä¾›åŸºæœ¬è§’è‰²åç§°ï¼ˆä¸åŒ…å«ä»»ä½•ç›®æ ‡ã€åŠ¨æœºå’Œé›†ä½“æ„å›¾ï¼‰
        basic_personas = "\n".join([f"- {p['name']}" for p in scenario['personas']])
        
        base_context = f"""
Scenario Description: {scenario['scenario_description']}

Character Settings:
{basic_personas}

Dialogue Content:
{dialogue_text}

Critical Moment: Turn {trigger['trigger_turn_id']} - {trigger['trigger_description']}
"""
        
        if task_type == "atmosphere_recognition":
            question = labels['atmosphere_recognition']
            return f"""{base_context}

Please analyze what the most prominent change in group atmosphere is after the critical moment.

Question: {question['question']}

Options:
{chr(10).join([f"{i+1}. {opt[3:]}" for i, opt in enumerate(question['mcq_options'])])}

Please only answer with the option number (1-6), no explanation needed."""

        elif task_type == "ky_test":
            question = labels['ky_test']
            return f"""{base_context}

Please analyze what the most appropriate response should be in the current situation.

Question: {question['question']}

Options:
{chr(10).join([f"{i+1}. {opt[3:]}" for i, opt in enumerate(question['mcq_options'])])}

Please only answer with the option number (1-6), no explanation needed."""

        elif task_type == "subtext_deciphering":
            question = labels['subtext_deciphering']
            return f"""{base_context}

Please analyze the subtext meaning in the following dialogue:

Question: {question['question']}

Options:
{chr(10).join([f"{i+1}. {opt[3:]}" for i, opt in enumerate(question['mcq_options'])])}

Please only answer with the option number (1-6), no explanation needed."""
        
        return ""
    
    def _parse_evaluation_response(self, response: str, sample: Dict, task_type: str) -> Dict:
        """è§£æè¯„æµ‹å“åº”"""
        # æå–æ•°å­—ç­”æ¡ˆ
        import re
        numbers = re.findall(r'\b([1-6])\b', response.strip())
        
        if not numbers:
            return {
                'predicted_answer': -1,
                'raw_response': response,
                'parse_error': True
            }
        
        predicted_answer = int(numbers[0]) - 1  # è½¬æ¢ä¸º0-basedç´¢å¼•
        
        # è·å–æ­£ç¡®ç­”æ¡ˆ
        correct_answer = sample['evaluation_labels'][task_type]['correct_answer_index']
        
        return {
            'predicted_answer': predicted_answer,
            'correct_answer': correct_answer,
            'is_correct': predicted_answer == correct_answer,
            'raw_response': response.strip(),
            'parse_error': False
        }
    
    def print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "="*60)
        print(f"ğŸ“Š åŒè¯­è¯„æµ‹å®¢æˆ·ç«¯ç»Ÿè®¡ä¿¡æ¯ ({'ä¸­æ–‡' if self.language == 'zh' else 'è‹±æ–‡'})")
        print("="*60)
        print(f"æ€»è¯·æ±‚æ•°: {self.stats['total_requests']}")
        print(f"æˆåŠŸè¯·æ±‚: {self.stats['successful_requests']}")
        print(f"å¤±è´¥è¯·æ±‚: {self.stats['failed_requests']}")
        print(f"æˆåŠŸç‡: {self.stats['successful_requests']/max(self.stats['total_requests'], 1)*100:.1f}%")
        print(f"å¯†é’¥åˆ‡æ¢æ¬¡æ•°: {self.stats['key_switches']}")
        print(f"é™æµå‘½ä¸­æ¬¡æ•°: {self.stats['rate_limit_hits']}")
        print(f"å½“å‰ä½¿ç”¨æ¨¡å‹: {self._get_current_model()}")
        if not self.use_agentworld:
            print(f"å½“å‰APIå¯†é’¥: {self.current_key_index + 1}/{len(self.api_keys)}")
            print(f"å¯†é’¥åˆ©ç”¨ç‡: {(self.current_key_index + 1)/len(self.api_keys)*100:.1f}%")
            print(f"å¹³å‡æ¯å¯†é’¥è¯·æ±‚æ•°: {self.stats['total_requests']/max(self.stats['key_switches'] + 1, 1):.1f}")
        print(f"å½“å‰å»¶è¿Ÿè®¾ç½®: {self.rate_limit_delay:.1f}ç§’")
        
        print(f"\næ¨¡å‹ä½¿ç”¨ç»Ÿè®¡:")
        for model, count in self.stats['model_usage'].items():
            print(f"  {model}: {count}æ¬¡")
        print("="*60)
    
    def _has_full_persona_info(self, sample: Dict) -> bool:
        """æ£€æŸ¥æ ·æœ¬æ˜¯å¦åŒ…å«å®Œæ•´çš„è§’è‰²ä¿¡æ¯ï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦å¯ä»¥ä½¿ç”¨å…¨çŸ¥è§†è§’ï¼‰"""
        try:
            scenario = sample.get('scenario_setup', {})
            personas = scenario.get('personas', [])
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è§’è‰²ä¿¡æ¯
            if not personas:
                return False
            
            # æ£€æŸ¥æ¯ä¸ªè§’è‰²æ˜¯å¦æœ‰å®Œæ•´ä¿¡æ¯
            for persona in personas:
                if not all(key in persona for key in ['name', 'public_goal', 'private_motive']):
                    return False
            
            # æ£€æŸ¥æ˜¯å¦æœ‰éšè—é›†ä½“æ„å›¾
            if 'hidden_collective_intent' not in scenario:
                return False
            
            return True
        except:
            return False
    
    def _build_chinese_chat_full_prompt(self, sample: Dict, task_type: str) -> str:
        """æ„å»ºä¸­æ–‡Chatæ¨¡å¼å…¨çŸ¥è§†è§’prompt"""
        scenario = sample['scenario_setup']
        dialogue = sample['dialogue_transcript']
        trigger = sample['evaluation_trigger']
        labels = sample['evaluation_labels']
        
        # æ„å»ºå¯¹è¯æ–‡æœ¬
        dialogue_text = "\n".join([
            f"Turn {turn['turn']}: {turn['speaker']}: {turn['line']}"
            for turn in dialogue
        ])
        
        base_context = f"""
åœºæ™¯æè¿°: {scenario['scenario_description']}

è§’è‰²è®¾å®š:
{chr(10).join([f"- {p['name']}: å…¬å¼€ç›®æ ‡({p['public_goal']}) | éšè—åŠ¨æœº({p['private_motive']})" for p in scenario['personas']])}

éšè—é›†ä½“æ„å›¾: {scenario['hidden_collective_intent']}

å¯¹è¯å†…å®¹:
{dialogue_text}

å…³é”®æ—¶åˆ»: Turn {trigger['trigger_turn_id']} - {trigger['trigger_description']}

æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªåŒ…å«é—²èŠå†…å®¹çš„å¯¹è¯åœºæ™¯ï¼Œè¯·æ³¨æ„åŒºåˆ†é—²èŠè¯é¢˜å’Œæ ¸å¿ƒå†²çªå†…å®¹ï¼Œé‡ç‚¹åˆ†æä¸ç¤¾äº¤äº’åŠ¨ç›¸å…³çš„éƒ¨åˆ†ã€‚
"""
        
        if task_type == "atmosphere_recognition":
            question = labels['atmosphere_recognition']
            return f"""{base_context}

é—®é¢˜: {question['question']}

é€‰é¡¹:
{chr(10).join([f"{i}. {option}" for i, option in enumerate(question['mcq_options'])])}

è¯·ä»”ç»†åˆ†æå¯¹è¯ä¸­çš„æ°›å›´å˜åŒ–ï¼Œç‰¹åˆ«æ³¨æ„é—²èŠå†…å®¹å¦‚ä½•å½±å“æ•´ä½“æ°›å›´ã€‚è¯·åªå›ç­”é€‰é¡¹ç¼–å·(0-{len(question['mcq_options'])-1})ã€‚"""

        elif task_type == "ky_test":
            question = labels['ky_test']
            return f"""{base_context}

é—®é¢˜: {question['question']}

é€‰é¡¹:
{chr(10).join([f"{i}. {option}" for i, option in enumerate(question['mcq_options'])])}

è¯·åˆ†æåœ¨è¿™ä¸ªåŒ…å«é—²èŠçš„å¤æ‚ç¤¾äº¤åœºæ™¯ä¸­ï¼Œä»€ä¹ˆæ˜¯æœ€åˆæ—¶å®œçš„å›åº”ã€‚è¯·åªå›ç­”é€‰é¡¹ç¼–å·(0-{len(question['mcq_options'])-1})ã€‚"""

        elif task_type == "subtext_deciphering":
            question = labels['subtext_deciphering']
            return f"""{base_context}

é—®é¢˜: {question['question']}

é€‰é¡¹:
{chr(10).join([f"{i}. {option}" for i, option in enumerate(question['mcq_options'])])}

è¯·æ·±å…¥åˆ†æå¯¹è¯ä¸­çš„æ½œå°è¯ï¼Œæ³¨æ„åŒºåˆ†é—²èŠå†…å®¹å’ŒçœŸæ­£çš„éšå«æ„å›¾ã€‚è¯·åªå›ç­”é€‰é¡¹ç¼–å·(0-{len(question['mcq_options'])-1})ã€‚"""
    
    def _build_english_chat_full_prompt(self, sample: Dict, task_type: str) -> str:
        """æ„å»ºè‹±æ–‡Chatæ¨¡å¼å…¨çŸ¥è§†è§’prompt"""
        scenario = sample['scenario_setup']
        dialogue = sample['dialogue_transcript']
        trigger = sample['evaluation_trigger']
        labels = sample['evaluation_labels']
        
        # æ„å»ºå¯¹è¯æ–‡æœ¬
        dialogue_text = "\n".join([
            f"Turn {turn['turn']}: {turn['speaker']}: {turn['line']}"
            for turn in dialogue
        ])
        
        base_context = f"""
Scenario Description: {scenario['scenario_description']}

Character Settings:
{chr(10).join([f"- {p['name']}: Public Goal({p['public_goal']}) | Hidden Motive({p['private_motive']})" for p in scenario['personas']])}

Hidden Collective Intent: {scenario['hidden_collective_intent']}

Dialogue Content:
{dialogue_text}

Key Moment: Turn {trigger['trigger_turn_id']} - {trigger['trigger_description']}

Note: This is a dialogue scenario that includes casual chat content. Please distinguish between casual topics and core conflict content, focusing on analyzing social interaction aspects.
"""
        
        if task_type == "atmosphere_recognition":
            question = labels['atmosphere_recognition']
            return f"""{base_context}

Question: {question['question']}

Options:
{chr(10).join([f"{i}. {option}" for i, option in enumerate(question['mcq_options'])])}

Please carefully analyze the atmospheric changes in the dialogue, paying special attention to how casual chat content affects the overall atmosphere. Please only answer with the option number (0-{len(question['mcq_options'])-1})."""

        elif task_type == "ky_test":
            question = labels['ky_test']
            return f"""{base_context}

Question: {question['question']}

Options:
{chr(10).join([f"{i}. {option}" for i, option in enumerate(question['mcq_options'])])}

Please analyze what would be the most appropriate response in this complex social scenario that includes casual chat. Please only answer with the option number (0-{len(question['mcq_options'])-1})."""

        elif task_type == "subtext_deciphering":
            question = labels['subtext_deciphering']
            return f"""{base_context}

Question: {question['question']}

Options:
{chr(10).join([f"{i}. {option}" for i, option in enumerate(question['mcq_options'])])}

Please deeply analyze the subtext in the dialogue, distinguishing between casual chat content and genuine hidden intentions. Please only answer with the option number (0-{len(question['mcq_options'])-1})."""

# ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™åŸæ¥çš„ç±»å
EvaluationClient = BilingualEvaluationClient
