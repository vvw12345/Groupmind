#!/usr/bin/env python3
"""
ä¸€é”®è¿è¡Œè¯„æµ‹è„šæœ¬
"""
import sys
import os
from pathlib import Path
from datetime import datetime

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

from evaluator import MultiThreadEvaluator

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="æ¨¡å‹è¯„æµ‹ç³»ç»Ÿ")
    parser.add_argument("--data", default="/home/Group/data_generator/data/benchmark_part1.json", 
                       help="æ•°æ®é›†æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--models", nargs="+", 
                       default=["z-ai/glm-4.5-air:free", "deepseek/deepseek-r1-distill-llama-70b:free"],
                       help="è¦è¯„æµ‹çš„æ¨¡å‹åˆ—è¡¨")
    parser.add_argument("--platform", choices=["openrouter", "siliconflow", "agentworld", "yunwu"], default="openrouter",
                       help="é€‰æ‹©APIå¹³å°: openrouter, siliconflow, agentworld æˆ– yunwu")
    parser.add_argument("--language", choices=["zh", "en"], default="zh",
                       help="æ•°æ®è¯­è¨€: zh (ä¸­æ–‡) æˆ– en (è‹±æ–‡)")
    parser.add_argument("--mode", choices=["full", "limited", "chat"], default="full",
                       help="è¯„ä¼°æ¨¡å¼: full (å…¨çŸ¥è§†è§’ï¼ŒåŒ…å«éšè—åŠ¨æœº), limited (æœ‰é™ä¿¡æ¯ï¼Œä»…åŸºæœ¬èº«ä»½), æˆ– chat (é—²èŠæ¨¡å¼ï¼ŒåŒ…å«å¹²æ‰°è¯é¢˜)")
    parser.add_argument("--workers", type=int, default=4, help="æœ€å¤§çº¿ç¨‹æ•°")
    parser.add_argument("--limit", type=int, default=None, 
                       help="é™åˆ¶è¯„æµ‹çš„æ ·æœ¬æ•°é‡ (ä¾‹å¦‚: --limit 500 åªè¯„æµ‹å‰500æ¡)")
    parser.add_argument("--start", type=int, default=1, 
                       help="ä»ç¬¬å‡ ä¸ªæ ·æœ¬å¼€å§‹è¯„æµ‹ (ä¾‹å¦‚: --start 18 ä»ç¬¬18ä¸ªæ ·æœ¬å¼€å§‹)")
    parser.add_argument("--output", default=None, help="ç»“æœè¾“å‡ºç›®å½•(é»˜è®¤ä½¿ç”¨æ—¶é—´æˆ³)")
    
    args = parser.parse_args()
    
    print("ğŸ¯ æ¨¡å‹è¯„æµ‹ç³»ç»Ÿ")
    print("="*60)
    
    # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°
    data_file = args.data
    models = args.models
    max_workers = args.workers
    sample_limit = args.limit
    start_sample = args.start
    language = args.language
    evaluation_mode = args.mode
    use_siliconflow = args.platform == "siliconflow"
    use_agentworld = args.platform == "agentworld"
    use_yunwu = args.platform == "yunwu"
    
    # ä½¿ç”¨æ—¶é—´æˆ³åˆ›å»ºå”¯ä¸€çš„ç»“æœç›®å½•
    if args.output:
        output_dir = args.output
    else:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = f"results_{timestamp}"
    
    print(f"ğŸ“Š æ•°æ®æ–‡ä»¶: {data_file}")
    print(f"ğŸ¤– è¯„æµ‹æ¨¡å‹: {', '.join(models)}")
    platform_name = "äº‘é›¾AI" if use_yunwu else ("AgentWorld" if use_agentworld else ("ç¡…åŸºæµåŠ¨" if use_siliconflow else "OpenRouter"))
    print(f"ğŸŒ APIå¹³å°: {platform_name}")
    print(f"ğŸŒ æ•°æ®è¯­è¨€: {'ä¸­æ–‡' if language == 'zh' else 'è‹±æ–‡'}")
    print(f"ğŸ” è¯„ä¼°æ¨¡å¼: {'å…¨çŸ¥è§†è§’' if evaluation_mode == 'full' else 'æœ‰é™ä¿¡æ¯'}")
    print(f"ğŸ§µ çº¿ç¨‹æ•°: {max_workers}")
    print(f"ğŸ¯ å¼€å§‹æ ·æœ¬: ç¬¬{start_sample}ä¸ª")
    if sample_limit:
        print(f"ğŸ“‹ æ ·æœ¬é™åˆ¶: æœ€å¤š{sample_limit}æ¡")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    if not Path(data_file).exists():
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        return
    
    # åˆ›å»ºè¯„æµ‹å™¨
    evaluator = MultiThreadEvaluator(models=models, max_workers=max_workers, use_siliconflow=use_siliconflow, use_agentworld=use_agentworld, use_yunwu=use_yunwu, language=language, evaluation_mode=evaluation_mode)
    
    # åŠ è½½æ•°æ®é›†
    samples = evaluator.load_dataset(data_file)
    if not samples:
        print("âŒ æ— æ³•åŠ è½½æ•°æ®é›†")
        return
    
    # åº”ç”¨å¼€å§‹ä½ç½®å’Œæ ·æœ¬æ•°é‡é™åˆ¶
    original_count = len(samples)
    
    # å…ˆåº”ç”¨å¼€å§‹ä½ç½®
    if start_sample > 1:
        if start_sample > len(samples):
            print(f"âŒ å¼€å§‹ä½ç½® {start_sample} è¶…å‡ºæ ·æœ¬æ€»æ•° {len(samples)}")
            return
        samples = samples[start_sample-1:]
        print(f"ğŸ¯ ä»ç¬¬{start_sample}ä¸ªæ ·æœ¬å¼€å§‹ï¼Œå‰©ä½™ {len(samples)} æ¡æ ·æœ¬")
    
    # å†åº”ç”¨æ•°é‡é™åˆ¶
    if sample_limit and sample_limit > 0:
        samples = samples[:sample_limit]
        print(f"ğŸ“‹ æ ·æœ¬é™åˆ¶: æœ€å¤šè¯„æµ‹ {len(samples)} æ¡")
    
    print(f"ğŸ“Š æœ€ç»ˆè¯„æµ‹æ ·æœ¬æ•°: {len(samples)} æ¡ (åŸå§‹æ€»æ•°: {original_count})")
    
    # æ˜¾ç¤ºæ ·æœ¬é™åˆ¶ä¿¡æ¯
    if sample_limit:
        print(f"âš ï¸  æ³¨æ„: ä½¿ç”¨ --limit {sample_limit} å‚æ•°ï¼Œåªè¯„æµ‹å‰{len(samples)}æ¡æ ·æœ¬")
    
    # ç¡®è®¤å¼€å§‹è¯„æµ‹
    print(f"\nå‡†å¤‡è¯„æµ‹ {len(samples)} ä¸ªæ ·æœ¬...")
    print(f"é¢„è®¡æ€»ä»»åŠ¡æ•°: {len(samples) * len(models) * 3}")
    
    response = input("æ˜¯å¦å¼€å§‹è¯„æµ‹? (y/N): ")
    if response.lower() != 'y':
        print("âŒ è¯„æµ‹å·²å–æ¶ˆ")
        return
    
    try:
        # æ‰§è¡Œè¯„æµ‹
        print(f"\nğŸš€ å¼€å§‹è¯„æµ‹...")
        # è¿è¡Œè¯„æµ‹
        try:
            evaluator.evaluate_dataset(
                samples=samples,
                output_dir=output_dir
            )
            # æ‰“å°å®¢æˆ·ç«¯ç»Ÿè®¡
            for model, client in evaluator.clients.items():
                print(f"\n{model} å®¢æˆ·ç«¯ç»Ÿè®¡:")
                client.print_stats()
        except Exception as e:
            print(f"\nâŒ è¯„æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
        
        print(f"\nğŸ‰ è¯„æµ‹å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ° {output_dir} ç›®å½•")
        
    except KeyboardInterrupt:
        print(f"\nâš ï¸ è¯„æµ‹è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ è¯„æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
